{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# load environment variables from .env file for project\n",
    "dotenv_path = Path('../.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "data_directory = os.getenv(\"OUTPUT_DIRECTORY\")\n",
    "feature_directory = os.path.join(data_directory, \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidl_df = pd.read_parquet(os.path.join(data_directory, \"ssi_lidl_revenue.parquet\"), engine=\"pyarrow\")\n",
    "lidl_df.rename(columns={\"bg_number\": \"supermarket_id\", \"ean_name\": \"receipt_text\"}, inplace=True)\n",
    "lidl_df.receipt_text = lidl_df.receipt_text.str.replace('[^0-9a-zA-Z.,-/ ]', '', regex=True).str.lstrip().str.rstrip().str.lower()\n",
    "lidl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidl_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_df = pd.read_parquet(os.path.join(data_directory, \"ssi_plus_revenue_receipts.parquet\"), engine=\"pyarrow\")\n",
    "plus_df.receipt_text = plus_df.receipt_text.str.replace('[^0-9a-zA-Z.,-/ ]', '', regex=True).str.lstrip().str.rstrip().str.lower()\n",
    "plus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_eans_lidl = set(lidl_df.ean_number.values.tolist())\n",
    "unique_eans_plus = set(plus_df.ean_number.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_eans_lidl), len(unique_eans_plus), len(unique_eans_lidl) + len(unique_eans_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_eans = unique_eans_plus.intersection(unique_eans_lidl)\n",
    "same_eans, len(same_eans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_texts_lidl = set(lidl_df.receipt_text)\n",
    "unique_texts_plus = set(plus_df.receipt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 1771 texts, even after cleaning the receipt texts\n",
    "\n",
    "same_texts = unique_texts_lidl.intersection(unique_texts_plus)\n",
    "same_texts, len(same_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(unique_texts_lidl) + len(unique_texts_plus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlap only 0.92 %, very small!\n",
    "\n",
    "len(same_texts) / (len(unique_texts_lidl) + len(unique_texts_plus)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_text_splits_lidl = set([word for receipt_text in unique_texts_lidl for word in receipt_text.split()])\n",
    "unique_text_splits_plus = set([word for receipt_text in unique_texts_plus for word in receipt_text.split()])\n",
    "len(unique_text_splits_lidl), len(unique_text_splits_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_text_splits_lidl.intersection(unique_text_splits_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_text_splits_lidl.intersection(unique_text_splits_plus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we split up the texts and look at the overlap of the separate words in both lidl and plus, overlap is only 9.6 %\n",
    "len(unique_text_splits_lidl.intersection(unique_text_splits_plus)) / (len(unique_text_splits_lidl) + len(unique_text_splits_plus)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_to_lidl = unique_text_splits_lidl.difference(unique_text_splits_plus)\n",
    "unique_to_lidl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_to_plus = unique_text_splits_plus.difference(unique_text_splits_lidl)\n",
    "unique_to_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(words_left: set, words_right_left) -> float:\n",
    "    return len(words_left.intersection(words_right_left)) / (len(words_left) + len(words_right_left)) * 100\n",
    "\n",
    "def process_plus(word: str) -> str:\n",
    "    #if 'eieren' not in word:\n",
    "    #    word = word.replace('eiere', 'eieren')\n",
    "    #if word.endswith('sal'):\n",
    "    #    word = word.replace('sal', 'salade')\n",
    "    return word.lower()\n",
    "\n",
    "def process_words_plus(words: set) -> set:\n",
    "    return set([process_plus(word) for word in words])\n",
    "    \n",
    "overlap_raw = overlap(unique_text_splits_lidl, unique_text_splits_plus)\n",
    "overlap_processed = overlap(process_words_plus(unique_text_splits_lidl), process_words_plus(unique_text_splits_plus))\n",
    "\n",
    "overlap_raw, overlap_processed, overlap_processed > overlap_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_product_descriptions = set(plus_df.ean_name)\n",
    "len(plus_product_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "[word for i, word in enumerate(plus_product_descriptions) if i < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_split_descriptions = set([word for description in plus_product_descriptions for word in description.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap(unique_texts_lidl, plus_product_descriptions), overlap(unique_text_splits_lidl, plus_split_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_length_df = pd.DataFrame({\n",
    "    \"word_length\": [len(word) for word in unique_text_splits_plus]\n",
    "})\n",
    "plus_length_df.plot.hist(column=\"word_length\", bins=plus_length_df.word_length.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_receipt_length_df = pd.DataFrame({\n",
    "    \"word_length\": [len(word) for word in plus_df.receipt_text]\n",
    "})\n",
    "plus_receipt_length_df.plot.hist(column=\"word_length\", bins=plus_receipt_length_df.word_length.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidl_length_df = pd.DataFrame({\n",
    "    \"word_length\": [len(word) for word in unique_text_splits_lidl]\n",
    "})\n",
    "lidl_length_df.plot.hist(column=\"word_length\", bins=lidl_length_df.word_length.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidl_receipt_length_df = pd.DataFrame({\n",
    "    \"word_length\": [len(word) for word in lidl_df.receipt_text]\n",
    "})\n",
    "lidl_receipt_length_df.plot.hist(column=\"word_length\", bins=lidl_receipt_length_df.word_length.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "def word_length_histograms(supermarket_names: List[str], supermarket_text_series: List[pd.Series]) -> pd.DataFrame:\n",
    "    text_length_per_supermarket = dict()\n",
    "    unique_word_lengths = set()\n",
    "    for supermarket_name, supermarket_texts in zip(supermarket_names, supermarket_text_series):    \n",
    "        all_word_lengths = [len(word) for word in supermarket_texts]\n",
    "        unique_word_lengths = unique_word_lengths.union(set(all_word_lengths))\n",
    "        text_length_per_supermarket[supermarket_name] = all_word_lengths\n",
    "    \n",
    "    min_word_length = min(unique_word_lengths)\n",
    "    max_word_length = max(unique_word_lengths)\n",
    "    \n",
    "    word_length_histogram_df = pd.DataFrame(index=sorted(unique_word_lengths))\n",
    "    for supermarket_name, word_lengths in  text_length_per_supermarket.items():  \n",
    "        hist, bin_edges = np.histogram(word_lengths, bins=len(unique_word_lengths))\n",
    "        word_length_histogram_df[f\"{supermarket_name}_word_lengths\"] = hist\n",
    "    \n",
    "    return word_length_histogram_df\n",
    "        \n",
    "receipt_length_hist = word_length_histograms([\"lidl\", \"plus\"], [lidl_df.receipt_text, plus_df.receipt_text])\n",
    "receipt_length_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix plot to show two overlapping bar plots.\n",
    "receipt_length_hist.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-governor",
   "metadata": {},
   "source": [
    "## Overlap per COICOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "coicop_lidl = lidl_df.coicop_level_1.unique()\n",
    "coicop_lidl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "coicop_plus = plus_df.coicop_level_1.unique()\n",
    "coicop_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "coicop_both = set(coicop_lidl).intersection(set(coicop_plus))\n",
    "coicop_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "coicop_overlap_dict = dict()\n",
    "for coicop in coicop_both:\n",
    "    lidl_texts = set(lidl_df[lidl_df.coicop_level_1 == coicop].receipt_text)\n",
    "    plus_texts = set(plus_df[plus_df.coicop_level_1 == coicop].receipt_text)\n",
    "    coicop_overlap_dict[coicop] = overlap(lidl_texts, plus_texts)\n",
    "coicop_overlap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "coicop_words_overlap_dict = dict()\n",
    "for coicop in coicop_both:\n",
    "    lidl_texts = set([word for receipt_text in lidl_df[lidl_df.coicop_level_1 == coicop].receipt_text for word in receipt_text.split()])\n",
    "    plus_texts = set([word for receipt_text in plus_df[plus_df.coicop_level_1 == coicop].receipt_text for word in receipt_text.split()])\n",
    "    coicop_words_overlap_dict[coicop] = overlap(lidl_texts, plus_texts)\n",
    "coicop_words_overlap_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssi",
   "language": "python",
   "name": "ssi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
