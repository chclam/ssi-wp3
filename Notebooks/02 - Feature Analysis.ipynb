{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables from .env file for project\n",
    "dotenv_path = Path('../.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = os.getenv(\"OUTPUT_DIRECTORY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidl_df = pd.read_parquet(os.path.join(data_directory, 'ssi_omzet_eans_coicops_lidl_2018_202308.parquet'), engine=\"pyarrow\")\n",
    "lidl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "feature_extractor_dict = {'CountVect': CountVectorizer(analyzer='word', token_pattern=r'\\w{2,}', max_features=5000),\n",
    "                               'TFIDF_word': TfidfVectorizer(analyzer='word', token_pattern=r'\\w{2,}', max_features=5000),\n",
    "                               'TFIDF_char': TfidfVectorizer(analyzer='char', token_pattern=r'\\w{2,}', ngram_range=(2,3), max_features=5000),\n",
    "                               'TFIDF_char34': TfidfVectorizer(analyzer='char', token_pattern=r'\\w{2,}', ngram_range=(3,4), max_features=5000),\n",
    "                               'Count_char': CountVectorizer(analyzer='char', token_pattern=r'\\w{2,}', max_features=5000)\n",
    "                               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidl_sample_df = lidl_df.sample(1000).reset_index(drop=True)\n",
    "lidl_sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def tsne_plot(dataframe: pd.DataFrame, feature_extractor, plot_title: str, text_column: str, label_column: str):\n",
    "    tsne = TSNE(n_components=2, init=\"random\", learning_rate=\"auto\")\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_true = label_encoder.fit_transform(dataframe[label_column].values)\n",
    "\n",
    "    features = feature_extractor.fit_transform(dataframe[text_column])\n",
    "    embedded_features = tsne.fit_transform(features)    \n",
    "    plt.scatter(embedded_features[:,0], embedded_features[:, 1], c=y_true)\n",
    "    plt.title(plot_title)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "for i, (name, extractor) in enumerate(feature_extractor_dict.items()):\n",
    "        #if i > 1:\n",
    "        #    break\n",
    "        tsne_plot(lidl_sample_df, extractor, name, \"ean_name\", \"coicop_division\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"nl_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidl_sample_df[\"ean_name\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(lidl_sample_df[\"ean_name\"][1])\n",
    "doc.vector.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, init=\"random\", learning_rate=\"auto\")\n",
    "label_encoder = LabelEncoder()\n",
    "y_true = label_encoder.fit_transform(lidl_sample_df[\"coicop_division\"].values)\n",
    "\n",
    "features = np.array([nlp(ean_name).vector for ean_name in lidl_sample_df[\"ean_name\"]])\n",
    "embedded_features = tsne.fit_transform(features)    \n",
    "plt.scatter(embedded_features[:,0], embedded_features[:, 1], c=y_true)\n",
    "plt.title(\"word embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_md = spacy.load(\"nl_core_news_md\")\n",
    "\n",
    "tsne = TSNE(n_components=2, init=\"random\", learning_rate=\"auto\")\n",
    "label_encoder = LabelEncoder()\n",
    "y_true = label_encoder.fit_transform(lidl_sample_df[\"coicop_division\"].values)\n",
    "\n",
    "features = np.array([nlp_md(ean_name).vector for ean_name in lidl_sample_df[\"ean_name\"]])\n",
    "embedded_features = tsne.fit_transform(features)    \n",
    "plt.scatter(embedded_features[:,0], embedded_features[:, 1], c=y_true)\n",
    "plt.title(\"word embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_lg = spacy.load(\"nl_core_news_lg\")\n",
    "\n",
    "\n",
    "tsne = TSNE(n_components=2, init=\"random\", learning_rate=\"auto\")\n",
    "label_encoder = LabelEncoder()\n",
    "y_true = label_encoder.fit_transform(lidl_sample_df[\"coicop_division\"].values)\n",
    "\n",
    "features = np.array([nlp_lg(ean_name).vector for ean_name in lidl_sample_df[\"ean_name\"]])\n",
    "embedded_features = tsne.fit_transform(features)    \n",
    "plt.scatter(embedded_features[:,0], embedded_features[:, 1], c=y_true)\n",
    "plt.title(\"word embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features_and_labels(nlp_model, dataframe: pd.DataFrame, text_column: str = \"ean_name\", label_column: str = \"coicop_division\") -> Tuple[LabelEncoder, pd.DataFrame]:\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_true = label_encoder.fit_transform(dataframe[label_column].values)\n",
    "\n",
    "    features = [nlp_model(ean_name).vector for ean_name in tqdm(dataframe[text_column])]\n",
    "    return label_encoder, pd.DataFrame({ \n",
    "        \"features\": features,\n",
    "        \"original_label\": dataframe[label_column],\n",
    "        \"label\": y_true\n",
    "    })\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lidl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(lidl_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = lidl_df.month.unique().tolist()\n",
    "months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_month = months[12]\n",
    "selected_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = sorted(list({month[:4] for month in months}))\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_year =  years[1]\n",
    "lidl_train_sample = lidl_df[lidl_df.month.str[:4] == selected_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder, features_df = extract_features_and_labels(nlp_md, lidl_train_sample)\n",
    "features_df.to_parquet(os.path.join(data_directory, \"ssi_lidl_features_spacy_nl_md.parquet\"), engine=\"pyarrow\")\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_data, test_data = train_test_split(features_df, test_size=0.2, stratify=features_df.label)\n",
    "train_val_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "lr_model = logistic_regression.fit(train_val_data.features.values.tolist(), train_val_data.label.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = label_encoder.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = lr_model.predict(test_data.features.values.tolist())\n",
    "\n",
    "print(classification_report(test_data.label.values, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidl_test = lidl_df.copy()\n",
    "\n",
    "lidl_test[\"label\"] = label_encoder.transform(lidl_test[\"coicop_division\"].values)\n",
    "lidl_test[\"features\"] = [nlp_md(ean_name).vector for ean_name in tqdm(lidl_test[\"ean_name\"], position=0, leave=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "year_array = []\n",
    "labels = []\n",
    "predictions = []\n",
    "f1_scores = []\n",
    "\n",
    "test_years = sorted(list({month[:4] for month in lidl_test.month}))\n",
    "for year in test_years:\n",
    "    year_df = lidl_test[lidl_test.month.str[:4] == year]\n",
    "    year_labels = year_df.label.values\n",
    "    year_features = year_df.features.values.tolist()\n",
    "    y_pred = lr_model.predict(year_features)\n",
    "    \n",
    "    year_array.extend([year for _ in range(len(year_labels))])\n",
    "    labels.extend(year_labels.tolist())\n",
    "    predictions.extend(y_pred.tolist())\n",
    "    f1_scores.append(f1_score(year_df.label.values, y_pred, average=\"weighted\"))\n",
    "    \n",
    "year_results_df = pd.DataFrame({\n",
    "    \"year\": year_array,\n",
    "    \"label\": labels,\n",
    "    \"prediction\": predictions\n",
    "})    \n",
    "    \n",
    "plt.plot(test_years, f1_scores)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_results_df = year_results_df.set_index([\"year\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_f1_score(row: pd.Series) -> float:\n",
    "    return f1_score(row.index.get_level_values(1), row, average=\"weighted\")\n",
    "    \n",
    "f1_scores_per_group = year_results_df.groupby(by=[\"year\", \"label\"]).agg(agg_f1_score)\n",
    "f1_scores_per_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_df = f1_scores_per_group.reset_index()\n",
    "f1_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = f1_scores_df.year.unique()\n",
    "labels = f1_scores_df.label.unique()\n",
    "\n",
    "f1_scores_per_group.unstack(level=1\n",
    "                           ).plot(subplots=True, rot=90, figsize=(10, 10), layout=(3,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssi",
   "language": "python",
   "name": "ssi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
